/**
 * ğŸµ AudioUtils - ì˜¤ë””ì˜¤ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
 * 
 * ì¤‘ë³µ ì½”ë“œ ì œê±°ë¥¼ ìœ„í•œ ì˜¤ë””ì˜¤ ê´€ë ¨ ê³µí†µ ê¸°ëŠ¥ ëª¨ìŒ
 * - AudioContext ê´€ë¦¬
 * - ì˜¤ë””ì˜¤ ë””ì½”ë”©
 * - ì˜¤ë””ì˜¤ ì••ì¶•
 * - ë©”ëª¨ë¦¬ ê´€ë¦¬
 */

class AudioUtils {
    constructor() {
        this.currentAudioContext = null;
    }

    /**
     * AudioContext ìƒì„± (ì‹±ê¸€í†¤ íŒ¨í„´)
     * @returns {AudioContext}
     */
    getAudioContext() {
        if (!this.currentAudioContext || this.currentAudioContext.state === 'closed') {
            this.currentAudioContext = new (window.AudioContext || window.webkitAudioContext)();
            window.currentAudioContext = this.currentAudioContext; // ì „ì—­ ì°¸ì¡° ì €ì¥
            console.log('ğŸµ ìƒˆë¡œìš´ AudioContext ìƒì„±');
        }
        return this.currentAudioContext;
    }

    /**
     * ì˜¤ë””ì˜¤ íŒŒì¼ì„ AudioBufferë¡œ ë””ì½”ë”©
     * @param {ArrayBuffer} arrayBuffer 
     * @returns {Promise<AudioBuffer>}
     */
    async decodeAudioData(arrayBuffer) {
        const audioContext = this.getAudioContext();
        try {
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            console.log(`âœ… ì˜¤ë””ì˜¤ ë””ì½”ë”© ì„±ê³µ: ${audioBuffer.duration.toFixed(1)}ì´ˆ, ${audioBuffer.sampleRate}Hz`);
            return audioBuffer;
        } catch (error) {
            console.error('âŒ ì˜¤ë””ì˜¤ ë””ì½”ë”© ì‹¤íŒ¨:', error);
            throw new Error(`ì˜¤ë””ì˜¤ ë””ì½”ë”© ì‹¤íŒ¨: ${error.message}`);
        }
    }

    /**
     * ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë¦¬ìƒ˜í”Œë§
     * @param {Float32Array} channelData 
     * @param {number} originalSampleRate 
     * @param {number} targetSampleRate 
     * @returns {Float32Array}
     */
    resampleAudio(channelData, originalSampleRate, targetSampleRate) {
        if (originalSampleRate === targetSampleRate) {
            return channelData;
        }

        const ratio = originalSampleRate / targetSampleRate;
        const newLength = Math.round(channelData.length / ratio);
        const result = new Float32Array(newLength);

        for (let i = 0; i < newLength; i++) {
            const sourceIndex = i * ratio;
            const index = Math.floor(sourceIndex);
            const fraction = sourceIndex - index;

            if (index + 1 < channelData.length) {
                result[i] = channelData[index] * (1 - fraction) + channelData[index + 1] * fraction;
            } else {
                result[i] = channelData[index];
            }
        }

        console.log(`ğŸ”„ ë¦¬ìƒ˜í”Œë§: ${originalSampleRate}Hz â†’ ${targetSampleRate}Hz (${channelData.length} â†’ ${newLength} ìƒ˜í”Œ)`);
        return result;
    }

    /**
     * Float32Arrayë¥¼ 16ë¹„íŠ¸ WAV í¬ë§·ìœ¼ë¡œ ë³€í™˜
     * @param {Float32Array} audioData 
     * @param {number} sampleRate 
     * @returns {ArrayBuffer}
     */
    encodeWAV(audioData, sampleRate) {
        const length = audioData.length;
        const buffer = new ArrayBuffer(44 + length * 2);
        const view = new DataView(buffer);

        // WAV í—¤ë” ì‘ì„±
        const writeString = (offset, string) => {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        };

        writeString(0, 'RIFF');
        view.setUint32(4, 36 + length * 2, true);
        writeString(8, 'WAVE');
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, 1, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * 2, true);
        view.setUint16(32, 2, true);
        view.setUint16(34, 16, true);
        writeString(36, 'data');
        view.setUint32(40, length * 2, true);

        // ì˜¤ë””ì˜¤ ë°ì´í„° ë³€í™˜ (Float32 â†’ Int16)
        let offset = 44;
        for (let i = 0; i < length; i++) {
            const sample = Math.max(-1, Math.min(1, audioData[i]));
            view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
            offset += 2;
        }

        return buffer;
    }

    /**
     * AudioBufferë¥¼ MediaRecorderë¡œ MP3 ì••ì¶•
     * @param {AudioBuffer} audioBuffer 
     * @returns {Promise<Blob>}
     */
    async encodeToMp3UsingMediaRecorder(audioBuffer) {
        const audioContext = this.getAudioContext();
        
        return new Promise((resolve, reject) => {
            try {
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                
                const destination = audioContext.createMediaStreamDestination();
                source.connect(destination);
                
                const mediaRecorder = new MediaRecorder(destination.stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                const chunks = [];
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        chunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    const blob = new Blob(chunks, { type: 'audio/webm' });
                    resolve(blob);
                };
                
                mediaRecorder.onerror = (error) => {
                    reject(new Error(`MediaRecorder ì˜¤ë¥˜: ${error.message}`));
                };
                
                mediaRecorder.start();
                source.start();
                
                setTimeout(() => {
                    mediaRecorder.stop();
                    source.stop();
                }, audioBuffer.duration * 1000 + 100);
                
            } catch (error) {
                reject(new Error(`MP3 ì••ì¶• ì‹¤íŒ¨: ${error.message}`));
            }
        });
    }

    /**
     * ì••ì¶• ìˆ˜ì¤€ ê²°ì • (Google STT ìµœì í™”)
     * @param {number} fileSizeMB 
     * @param {number} durationMinutes 
     * @param {number} sampleRate 
     * @returns {Object}
     */
    determineCompressionLevel(fileSizeMB, durationMinutes, sampleRate) {
        if (fileSizeMB <= 5) {
            return {
                targetSampleRate: Math.min(sampleRate, 22050),
                compressionLevel: 'ê²½ëŸ‰ ì••ì¶•',
                quality: 'ê³ í’ˆì§ˆ ìœ ì§€'
            };
        } else if (fileSizeMB <= 15) {
            return {
                targetSampleRate: 16000,
                compressionLevel: 'í‘œì¤€ ì••ì¶•',
                quality: 'ê· í˜• ìµœì í™”'
            };
        } else if (fileSizeMB <= 30) {
            return {
                targetSampleRate: 16000,
                compressionLevel: 'ê°•ë ¥ ì••ì¶•',
                quality: 'í¬ê¸° ìš°ì„ '
            };
        } else {
            return {
                targetSampleRate: 8000,
                compressionLevel: 'ìµœëŒ€ ì••ì¶•',
                quality: 'í¬ê¸° ìµœìš°ì„ '
            };
        }
    }

    /**
     * ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë°”ì´íŠ¸ ë‹¨ìœ„ë¡œ ë¶„í• 
     * @param {ArrayBuffer} audioBuffer 
     * @param {number} maxChunkSize 
     * @returns {ArrayBuffer[]}
     */
    splitAudioByBytes(audioBuffer, maxChunkSize = 9 * 1024 * 1024) {
        const chunks = [];
        const totalSize = audioBuffer.byteLength;
        
        if (totalSize <= maxChunkSize) {
            return [audioBuffer];
        }
        
        for (let offset = 0; offset < totalSize; offset += maxChunkSize) {
            const chunkSize = Math.min(maxChunkSize, totalSize - offset);
            const chunk = audioBuffer.slice(offset, offset + chunkSize);
            chunks.push(chunk);
        }
        
        console.log(`ğŸ”„ ë°”ì´íŠ¸ ë¶„í• : ${totalSize}ë°”ì´íŠ¸ â†’ ${chunks.length}ê°œ ì¡°ê°`);
        return chunks;
    }

    /**
     * AudioContext ì •ë¦¬
     */
    async cleanup() {
        if (this.currentAudioContext && this.currentAudioContext.state !== 'closed') {
            await this.currentAudioContext.close();
            console.log('ğŸµ AudioContext ì •ë¦¬ ì™„ë£Œ');
        }
        this.currentAudioContext = null;
        window.currentAudioContext = null;
    }

    /**
     * íŒŒì¼ í¬ê¸°ë¥¼ MB ë‹¨ìœ„ë¡œ í¬ë§·
     * @param {number} bytes 
     * @returns {string}
     */
    formatFileSize(bytes) {
        const mb = bytes / (1024 * 1024);
        return `${mb.toFixed(2)}MB`;
    }

    /**
     * ì••ì¶•ë¥  ê³„ì‚°
     * @param {number} originalSize 
     * @param {number} compressedSize 
     * @returns {string}
     */
    calculateCompressionRatio(originalSize, compressedSize) {
        const ratio = ((originalSize - compressedSize) / originalSize * 100);
        return `${ratio.toFixed(1)}%`;
    }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
const audioUtils = new AudioUtils();

// ES6 ëª¨ë“ˆê³¼ ì „ì—­ ìŠ¤ì½”í”„ ëª¨ë‘ ì§€ì›
if (typeof module !== 'undefined' && module.exports) {
    module.exports = audioUtils;
} else {
    window.audioUtils = audioUtils;
}

// ES6 ëª¨ë“ˆ export ì¶”ê°€
export default audioUtils; 