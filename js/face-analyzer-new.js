// js/face-analyzer-new.js
// "ì„¸ê³„ ìµœê³ "ë¥¼ ì§€í–¥í•˜ëŠ” ì „ë¬¸ê°€ìš© ì–¼êµ´ ë¶„ì„ ì—”ì§„

import { state, workLogManager } from './state.js';
// ğŸ’¡ `face-analysis.js`ì—ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
import { ensureLibrariesLoaded } from './face-analysis.js';

function getModelBasePath() {
    try {
        const hostname = window.location.hostname;
        const port = window.location.port;
        if (hostname === 'localhost' && port === '5173') return '/models';
        if (hostname === 'localhost' && port === '3000') return '/AutoShortsWeb/public/models';
        if (hostname === 'twinverse.org' || hostname === 'www.twinverse.org') return '/AutoShortsWeb/models';
        return '/models';
    } catch (e) {
        return '/models';
    }
}
const MODEL_URL = getModelBasePath();
let modelsLoaded = false;
let isAnalyzing = false;

// ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ì´ˆê¸°í™” í•¨ìˆ˜
export function initializeFaceAnalyzer() {
    console.log('ğŸ­ Face analyzer V2 system initializing...');
    
    requestAnimationFrame(() => {
        requestAnimationFrame(async () => {
            try {
                initializeUIElements();
                await loadModels();
                console.log('âœ… Face analyzer V2 system initialized successfully');
            } catch (error) {
                console.error('âŒ Failed to initialize face analyzer V2 system:', error);
            }
        });
    });
}

// --- UI Elements ---
let videoEl;
let progressContainer;
let progressText;
let progressBarFill;
let resultsContainer;
let analyzeBtn;
let mergeBtn; 
let mergeControls;

let currentActors = [];

function initializeUIElements() {
    videoEl = document.getElementById('videoPreview');
    progressContainer = document.getElementById('faceAnalysisProgressContainer'); 
    progressText = document.getElementById('faceAnalysisProgressText');
    progressBarFill = document.getElementById('faceAnalysisProgressBar');
    resultsContainer = document.getElementById('faceAnalysisResults');
    analyzeBtn = document.getElementById('analyzeFacesBtnV2'); 
    mergeBtn = document.getElementById('mergeBtn');
    mergeControls = document.getElementById('mergeControls');
    
    if (!progressContainer || !progressText || !progressBarFill || !resultsContainer) {
        console.error("Face Analyzer V2ì˜ í•„ìˆ˜ UI ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        throw new Error("UI ì´ˆê¸°í™” ì‹¤íŒ¨");
    }

    console.log('ğŸ­ Face analyzer V2 UI elements initialized');
}

function updateState(newState) {
    Object.assign(state.v2FaceAnalysis, newState);
    console.log('Face analysis state updated:', state.v2FaceAnalysis);
}

/**
 * ì „ë¬¸ê°€ ë¶„ì„ì— í•„ìš”í•œ ëª¨ë“  AI ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
 */
async function loadModels() {
    if (modelsLoaded) return true;
    
    // ğŸ’¡ `faceapi.js` ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¡œë“œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    await ensureLibrariesLoaded();

    if (!progressText || !progressContainer) {
        console.error("loadModels: UI ìš”ì†Œê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
        return false;
    }

    const progressPayload = {
        progressText: 'ì „ë¬¸ê°€ìš© ë¶„ì„ ëª¨ë¸ ë¡œë”© ì¤‘...',
        progress: 0
    };
    updateState(progressPayload);
    progressText.textContent = progressPayload.progressText;
    progressContainer.style.display = 'block';

    try {
        console.log('â³ V2(ì „ë¬¸ê°€) ëª¨ë¸ ë¡œë”© ì‹œì‘...');
        // ğŸ’¡ ì´ì œ 'faceapi'ëŠ” í•­ìƒ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
        await Promise.all([
            faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL),
            faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
            faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
            faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),
            faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
        ]);
        modelsLoaded = true;
        progressText.textContent = 'ì „ë¬¸ê°€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.';
        setTimeout(() => { progressContainer.style.display = 'none'; }, 2000);
        console.log('âœ… V2(ì „ë¬¸ê°€) ëª¨ë¸ ë¡œë”© ì™„ë£Œ.');
        return true;
    } catch (error) {
        console.error('âŒ V2(ì „ë¬¸ê°€) ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨:', error);
        progressText.textContent = 'ì˜¤ë¥˜: ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨';
        updateState({ status: 'error', error: 'ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' });
        alert('ì–¼êµ´ ë¶„ì„ ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
        return false;
    }
}

// (displayResults, handleMerge, startAnalysis í•¨ìˆ˜ë“¤ì€ ë³€ê²½ ì—†ìŒ)
function displayResults(actors, duration) {
    resultsContainer.innerHTML = '';
    currentActors = actors; 

    updateState({ actors: actors, status: 'completed', progress: 100 });
    
    if (actors.length === 0) {
        resultsContainer.innerHTML = '<p style="text-align: center; color: #888;">ì˜ìƒì—ì„œ ì¸ë¬¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.</p>';
        if (mergeControls) mergeControls.style.display = 'none';
        return;
    }

    if (mergeControls) mergeControls.style.display = 'block';
    if (mergeBtn) mergeBtn.disabled = true;

    actors.sort((a, b) => b.totalAppearances - a.totalAppearances);

    actors.forEach((actor, index) => {
        const emotions = Object.entries(actor.emotionSummary)
            .sort(([, a], [, b]) => b - a)
            .map(([emotion, count]) => `${emotion}(${count})`)
            .join(', ');

        const timelineMarkers = actor.appearances.map(time =>
            `<div class="timeline-marker" style="left: ${(time / duration) * 100}%;" data-time="${time}"></div>`
        ).join('');

        const actorCard = document.createElement('div');
        actorCard.className = 'face-card professional';
        actorCard.dataset.actorId = actor.id;
        actorCard.innerHTML = `
            <div class="face-card-selection">
                <input type="checkbox" class="actor-checkbox" data-actor-id="${actor.id}">
            </div>
            <img src="${actor.image}" alt="${actor.label}" class="face-card-img">
            <div class="face-card-content">
                <div class="face-card-header">
                    <div class="face-card-title">
                        <h4>${actor.label}</h4>
                        <p>ì¶”ì •: ${actor.gender}, ì•½ ${Math.round(actor.avgAge)}ì„¸</p>
                    </div>
                </div>
                <div class="face-card-body">
                    <p><strong>ì´ ë“±ì¥ íšŸìˆ˜:</strong> ${actor.totalAppearances}íšŒ</p>
                    <p><strong>ì£¼ìš” ê°ì •:</strong> ${emotions || 'ë¶„ì„ ì •ë³´ ì—†ìŒ'}</p>
                    <p><strong>ë“±ì¥ íƒ€ì„ë¼ì¸:</strong></p>
                    <div class="timeline-container">${timelineMarkers}</div>
                </div>
            </div>
        `;
        resultsContainer.appendChild(actorCard);
    });

    resultsContainer.querySelectorAll('.timeline-marker').forEach(marker => {
        marker.addEventListener('click', (e) => {
            const time = parseFloat(e.target.dataset.time);
            if (videoEl) {
                videoEl.currentTime = time;
                videoEl.play(); 
                setTimeout(() => videoEl.pause(), 500);
            }
        });
    });

    resultsContainer.querySelectorAll('.actor-checkbox').forEach(checkbox => {
        checkbox.addEventListener('change', () => {
            const selectedCount = resultsContainer.querySelectorAll('.actor-checkbox:checked').length;
            if (mergeBtn) mergeBtn.disabled = selectedCount < 2;

            const card = checkbox.closest('.face-card');
            if (checkbox.checked) {
                card.classList.add('selected');
            } else {
                card.classList.remove('selected');
            }
        });
    });
}

function handleMerge() {
    const selectedCheckboxes = resultsContainer.querySelectorAll('.actor-checkbox:checked');
    if (selectedCheckboxes.length < 2) {
        alert('ë³‘í•©í•˜ë ¤ë©´ ë‘ ëª… ì´ìƒì˜ ì¸ë¬¼ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.');
        return;
    }

    const selectedActorIds = Array.from(selectedCheckboxes).map(cb => cb.dataset.actorId);
    
    const actorsToMerge = currentActors.filter(actor => selectedActorIds.includes(actor.id));
    const remainingActors = currentActors.filter(actor => !selectedActorIds.includes(actor.id));

    const mergedDetections = actorsToMerge.flatMap(actor => actor.detections);
    
    const bestDetection = mergedDetections.reduce((best, current) => 
        current.detection.box.area > best.detection.box.area ? current : best
    );

    const faceCanvas = document.createElement('canvas');
    videoEl.currentTime = bestDetection.timestamp;
    videoEl.onseeked = () => { 
        const { x, y, width, height } = bestDetection.detection.box;
        const widthScale = 1.5, heightScale = 2.0;
        const newWidth = width * widthScale, newHeight = height * heightScale;
        let newX = x - (newWidth - width) / 2, newY = y - (newHeight - height) / 3;
        newX = Math.max(0, newX);
        newY = Math.max(0, newY);
        const finalWidth = Math.min(newWidth, videoEl.videoWidth - newX);
        const finalHeight = Math.min(newHeight, videoEl.videoHeight - newY);
        faceCanvas.width = finalWidth;
        faceCanvas.height = finalHeight;
        faceCanvas.getContext('2d', { willReadFrequently: true }).drawImage(videoEl, newX, newY, finalWidth, finalHeight, 0, 0, finalWidth, finalHeight);

        const gender = mergedDetections.map(d => d.gender).sort((a,b) => mergedDetections.filter(v => v.gender===a).length - mergedDetections.filter(v => v.gender===b).length).pop();
        const avgAge = mergedDetections.reduce((sum, d) => sum + d.age, 0) / mergedDetections.length;
        const emotionSummary = {};
        mergedDetections.forEach(d => {
            const topEmotion = Object.keys(d.expressions).reduce((a, b) => d.expressions[a] > d.expressions[b] ? a : b);
            emotionSummary[topEmotion] = (emotionSummary[topEmotion] || 0) + 1;
        });

        const mergedActor = {
            id: `actor-${Date.now()}-${Math.random()}`,
            label: actorsToMerge[0].label,
            image: faceCanvas.toDataURL(),
            gender: gender === 'male' ? 'ë‚¨ì„±' : 'ì—¬ì„±',
            avgAge: avgAge,
            emotionSummary: emotionSummary,
            totalAppearances: mergedDetections.length,
            appearances: mergedDetections.map(d => d.timestamp).sort((a,b) => a - b),
            detections: mergedDetections
        };

        const newActorList = [mergedActor, ...remainingActors];
        displayResults(newActorList, videoEl.duration);
        
        workLogManager.addWorkLog('face-analysis', `ì¸ë¬¼ ë³‘í•©: ${actorsToMerge.map(a => a.label).join(', ')} -> ${mergedActor.label}`);
    };
}

export async function startAnalysis() {
    if (isAnalyzing) {
        alert('ë¶„ì„ì´ ì´ë¯¸ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.');
        return;
    }
    isAnalyzing = true;
    
    updateState({ status: 'analyzing', progress: 0, progressText: 'ë¶„ì„ ì¤€ë¹„ ì¤‘...', actors: [], error: null });

    initializeUIElements();

    // ë¶„ì„ ì‹œì‘ ì‹œ ì»¨í…Œì´ë„ˆ í‘œì‹œ
    const v2Container = document.getElementById('faceAnalysisV2Container');
    if (v2Container) v2Container.style.display = 'block';

    if (mergeBtn) mergeBtn.addEventListener('click', handleMerge);

    resultsContainer.innerHTML = '<p style="text-align: center; color: #888;">ì „ë¬¸ê°€ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì •í™•ë„ë¥¼ ìœ„í•´ ì‹œê°„ì´ ì˜¤ë˜ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...</p>';
    if (analyzeBtn) {
        analyzeBtn.disabled = true;
        analyzeBtn.textContent = 'ë¶„ì„ ì¤‘...';
    }
    progressBarFill.style.width = '0%';
    progressContainer.style.display = 'block';

    if (!state.uploadedFile || !videoEl.src) {
        alert('ë¨¼ì € ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.');
        updateState({ status: 'error', error: 'ë™ì˜ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'});
        isAnalyzing = false;
        if (analyzeBtn) analyzeBtn.disabled = false;
        if (analyzeBtn) analyzeBtn.textContent = 'ì–¼êµ´ ë¶„ì„ (V2)';
        if (mergeControls) mergeControls.style.display = 'none';
        return;
    }

    if (!await loadModels()) {
        updateState({ status: 'idle' });
        isAnalyzing = false;
        if (analyzeBtn) analyzeBtn.disabled = false;
        if (analyzeBtn) analyzeBtn.textContent = 'ì–¼êµ´ ë¶„ì„ (V2)';
        progressContainer.style.display = 'none';
        if (mergeControls) mergeControls.style.display = 'none';
        return;
    }

    await new Promise(resolve => {
        if (videoEl.readyState >= 2) return resolve();
        videoEl.onloadeddata = () => resolve();
    });
    videoEl.pause();
    videoEl.currentTime = 0;

    const SAMPLING_RATE_FPS = 2;
    const interval = 1 / SAMPLING_RATE_FPS;
    const allDetections = [];

    const tempCanvas = document.createElement('canvas');
    const tempCtx = tempCanvas.getContext('2d', { willReadFrequently: true });
    tempCanvas.width = videoEl.videoWidth;
    tempCanvas.height = videoEl.videoHeight;

    for (let time = 0; time < videoEl.duration; time += interval) {
        videoEl.currentTime = time;
        await new Promise(resolve => { videoEl.onseeked = () => resolve(); });

        tempCtx.drawImage(videoEl, 0, 0, tempCanvas.width, tempCanvas.height);

        const detections = await faceapi
            .detectAllFaces(tempCanvas, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
            .withFaceLandmarks()
            .withFaceExpressions()
            .withAgeAndGender()
            .withFaceDescriptors();

        detections.forEach(d => {
            d.timestamp = time;
            allDetections.push(d);
        });

        const progress = (time / videoEl.duration) * 100;
        const progressTextContent = `ì •ë°€ ë¶„ì„ ì¤‘... (${Math.round(progress)}%)`;
        
        progressBarFill.style.width = `${progress}%`;
        progressBarFill.parentElement.setAttribute('aria-valuenow', progress.toFixed(0));
        progressText.textContent = progressTextContent;
        updateState({ progress: progress, progressText: progressTextContent });
    }

    if (allDetections.length === 0) {
        displayResults([], videoEl.duration);
        updateState({ status: 'completed' });
        isAnalyzing = false;
        if (analyzeBtn) analyzeBtn.disabled = false;
        if (analyzeBtn) analyzeBtn.textContent = 'ì–¼êµ´ ë¶„ì„ (V2)';
        progressContainer.style.display = 'none';
        return;
    }

    const clusteringProgressText = 'íƒì§€ëœ ì–¼êµ´ ê·¸ë£¹í™” ì‹œì‘...';
    progressText.textContent = clusteringProgressText;
    updateState({ progressText: clusteringProgressText });

    const actors = [];
    const DISTANCE_THRESHOLD = 0.5;

    progressBarFill.style.width = '0%';
    const totalDetections = allDetections.length;

    for (const [index, detection] of allDetections.entries()) {
        let bestMatch = null;
        let minDistance = 1;

        const progress = ((index + 1) / totalDetections) * 100;
        const progressTextContent = `ì–¼êµ´ ê·¸ë£¹í™” ì§„í–‰ ì¤‘... (${index + 1}/${totalDetections})`;
        progressBarFill.style.width = `${progress}%`;
        progressBarFill.parentElement.setAttribute('aria-valuenow', progress.toFixed(0));
        progressText.textContent = progressTextContent;
        updateState({ progress: progress, progressText: progressTextContent });

        for (let i = 0; i < actors.length; i++) {
            const dist = faceapi.euclideanDistance(detection.descriptor, actors[i].avgDescriptor);
            if (dist < minDistance) {
                minDistance = dist;
                bestMatch = actors[i];
            }
        }

        if (bestMatch && minDistance < DISTANCE_THRESHOLD) {
            bestMatch.detections.push(detection);
            const newDescriptors = bestMatch.detections.map(d => d.descriptor);
            const avgDescriptor = new Float32Array(newDescriptors[0].length);
            for (let i = 0; i < avgDescriptor.length; i++) {
                avgDescriptor[i] = newDescriptors.reduce((sum, desc) => sum + desc[i], 0) / newDescriptors.length;
            }
            bestMatch.avgDescriptor = avgDescriptor;
        } else {
            actors.push({
                id: `actor-${Date.now()}-${Math.random()}`,
                label: `ì¸ë¬¼ #${actors.length + 1}`,
                detections: [detection],
                avgDescriptor: detection.descriptor,
            });
        }
    }

    const aggregationProgressText = 'ìµœì¢… ë°ì´í„° ì§‘ê³„ ì‹œì‘...';
    progressText.textContent = aggregationProgressText;
    updateState({ progressText: aggregationProgressText });

    const finalActors = [];

    progressBarFill.style.width = '0%';
    const totalActors = actors.length;

    for (const [index, actor] of actors.entries()) {
        const progress = ((index + 1) / totalActors) * 100;
        const progressTextContent = `ì¸ë¬¼ë³„ Best Shot ì„ ì • ë° ì •ë³´ ì •ë¦¬ ì¤‘... (${index + 1}/${totalActors}ëª…)`;
        progressBarFill.style.width = `${progress}%`;
        progressBarFill.parentElement.setAttribute('aria-valuenow', progress.toFixed(0));
        progressText.textContent = progressTextContent;
        updateState({ progress: progress, progressText: progressTextContent });

        const bestDetection = actor.detections.reduce((best, current) =>
            current.detection.box.area > best.detection.box.area ? current : best
        );

        videoEl.currentTime = bestDetection.timestamp;
        await new Promise(resolve => { videoEl.onseeked = () => resolve(); });

        const faceCanvas = document.createElement('canvas');
        const { x, y, width, height } = bestDetection.detection.box;

        const widthScale = 1.5;
        const heightScale = 2.0;
        const newWidth = width * widthScale;
        const newHeight = height * heightScale;

        let newX = x - (newWidth - width) / 2;
        let newY = y - (newHeight - height) / 3;

        newX = Math.max(0, newX);
        newY = Math.max(0, newY);
        const finalWidth = Math.min(newWidth, videoEl.videoWidth - newX);
        const finalHeight = Math.min(newHeight, videoEl.videoHeight - newY);

        faceCanvas.width = finalWidth;
        faceCanvas.height = finalHeight;
        faceCanvas.getContext('2d', { willReadFrequently: true }).drawImage(videoEl, newX, newY, finalWidth, finalHeight, 0, 0, finalWidth, finalHeight);

        const gender = actor.detections.map(d => d.gender).sort((a,b) => actor.detections.filter(v => v.gender===a).length - actor.detections.filter(v => v.gender===b).length).pop();
        const avgAge = actor.detections.reduce((sum, d) => sum + d.age, 0) / actor.detections.length;

        const emotionSummary = {};
        actor.detections.forEach(d => {
            const topEmotion = Object.keys(d.expressions).reduce((a, b) => d.expressions[a] > d.expressions[b] ? a : b);
            emotionSummary[topEmotion] = (emotionSummary[topEmotion] || 0) + 1;
        });

        finalActors.push({
            id: actor.id,
            label: actor.label,
            image: faceCanvas.toDataURL(),
            gender: gender === 'male' ? 'ë‚¨ì„±' : 'ì—¬ì„±',
            avgAge: avgAge,
            emotionSummary: emotionSummary,
            totalAppearances: actor.detections.length,
            appearances: actor.detections.map(d => d.timestamp).sort((a,b) => a - b),
            detections: actor.detections
        });
    }

    displayResults(finalActors, videoEl.duration);
    workLogManager.addWorkLog('face-analysis', `V2 ì–¼êµ´ ë¶„ì„ ì™„ë£Œ: ${finalActors.length}ëª… ì‹ë³„`);
    isAnalyzing = false;
    if (analyzeBtn) {
        analyzeBtn.disabled = false;
        analyzeBtn.textContent = 'ì–¼êµ´ ë¶„ì„ (V2)';
    }
    progressContainer.style.display = 'none';

    console.log('âœ… V2(ì „ë¬¸ê°€) ì–¼êµ´ ë¶„ì„ ì™„ë£Œ.');
}
